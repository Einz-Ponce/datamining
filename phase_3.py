# -*- coding: utf-8 -*-
"""Phase 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HSjWXeVOmbXKOCL_AxEWaNO-FBgQZgHh
"""

!pip install xgboost
!pip install tensorflow
!pip install lightgbm

# Import Necessary Libraries
import pandas as pd # Imports the pandas library for data manipulation, aliased as 'pd'
import numpy as np # Imports the numpy library for numerical computations, aliased as 'np'
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder, StandardScaler,  PolynomialFeatures # Imports specific preprocessing tools from scikit-learn
from sklearn.decomposition import PCA # Imports Principal Component Analysis for dimensionality reduction
from sklearn.feature_selection import SelectKBest, f_classif # Imports feature selection tools
from sklearn.impute import SimpleImputer # Imports the SimpleImputer class for handling missing values
from scipy.stats import chi2_contingency, f_oneway # Imports statistical tests
from scipy.stats import pearsonr # Imports the Pearson correlation function
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.dummy import DummyRegressor
import lightgbm as lgb
from sklearn.datasets import fetch_california_housing

df = pd.read_csv('AHHH.csv', encoding='latin-1') # Reads the CSV file into a pandas DataFrame

print(df)

df.dropna(inplace=True)

"""#Phase 3:(step 2) Model Training"""

# 1. Train-Test Split
# Assuming 'IMDb' is your target variable:
# Replace problematic column names with actual column names from your DataFrame
X = df.drop(['IMDb', 'Title Name', 'ï»¿User_id', 'Language(Binary)', 'Age Rating'], axis=1)  # Corrected column names
y = df['IMDb']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80/20 split

"""linear regression model"""

lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

"""random forest regression"""

rf_model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)
rf_model.fit(X_train, y_train)

"""XGB regression"""

xgb_model = xgb.XGBRegressor(objective="reg:squarederror", n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
xgb_model.fit(X_train, y_train)

"""neural network"""

nn_model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dense(1)  # Output layer for regression
])

nn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])
nn_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)

"""lightGBM"""

model = lgb.LGBMRegressor(
    objective='regression',
    learning_rate=0.1,
    max_depth=7,
    num_leaves=31,
    n_estimators=200
)

# Create the early stopping callback
early_stopping = lgb.early_stopping(stopping_rounds=10, verbose=True)

# Fit the model, passing the early stopping callback in the 'callbacks' parameter
# Remove verbose=10 and let early_stopping control verbosity
model.fit(X_train, y_train, eval_set=[(X_test, y_test)], callbacks=[early_stopping])

"""#Phase 3: (step 3)Model Evaluation"""

def evaluate_model(name, y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return f"{name} -> MSE: {mse:.4f}, R²: {r2:.4f}"

lr_pred = lr_model.predict(X_test)
rf_pred = rf_model.predict(X_test)
xgb_pred = xgb_model.predict(X_test)
nn_pred = nn_model.predict(X_test).flatten()
y_pred = model.predict(X_test)

print(evaluate_model("Linear Regression", y_test, lr_pred))
print(evaluate_model("Random Forest", y_test, rf_pred))
print(evaluate_model("XGBoost", y_test, xgb_pred))
print(evaluate_model("Neural Network", y_test, nn_pred))
print(evaluate_model("Light GBM", y_test, y_pred))

"""#Step 4: Model Improvement"""